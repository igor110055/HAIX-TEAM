{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PaK7QUNGAUKB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import copy\n",
        "import string "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_text(text):\n",
        "    \"\"\"\n",
        "    process the text and filter some special symbol\n",
        "    :param text:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # string preprocessing and aspect term will not be processed\n",
        "    # text=str(text)\n",
        "    dot_exist = ('.' in text)\n",
        "    cur_text = text.replace('.', '')\n",
        "    cur_text = cur_text.replace('-', ' ')\n",
        "    cur_text = cur_text.replace(' - ', ' , ').strip()\n",
        "    cur_text = cur_text.replace('- ', ' ').strip()\n",
        "\n",
        "    # split words and punctuations\n",
        "    if '? ' not in cur_text:\n",
        "        cur_text = cur_text.replace('?', ' ? ').strip()\n",
        "    if '! ' not in cur_text:\n",
        "        cur_text = cur_text.replace('!', ' ! ').strip()\n",
        "    cur_text = cur_text.replace('(', '')\n",
        "    cur_text = cur_text.replace(')', '')\n",
        "    cur_text = cur_text.replace('...', ' , ').strip(' . ').strip().strip(' , ')\n",
        "    # remove quote\n",
        "    cur_text = cur_text.replace('\"', '')\n",
        "    cur_text = cur_text.replace(\" '\", \" \")\n",
        "    cur_text = cur_text.replace(\"' \", \" \")\n",
        "\n",
        "    cur_text = cur_text.replace(':', ' , ')\n",
        "    if dot_exist:\n",
        "        cur_text += ' .'\n",
        "        # correct some typos\n",
        "    # mainly for processing English texts\n",
        "    cur_text = cur_text.replace('cant', \"can't\")\n",
        "    cur_text = cur_text.replace('wouldnt', \"wouldn't\")\n",
        "    cur_text = cur_text.replace('dont', \"don't\")\n",
        "    cur_text = cur_text.replace('didnt', \"didn't\")\n",
        "    cur_text = cur_text.replace(\"you 're\", \"you're\")\n",
        "\n",
        "    # replace some special symbol\n",
        "    cur_text = cur_text.replace(u' ‚Äì ', ' , ').strip()\n",
        "\n",
        "    cur_text = cur_text.replace(u\"‚Äò\", \"\")\n",
        "    # filter the non-ascii character\n",
        "    cur_text = ''.join([ch if ord(ch) < 128 else ' ' for ch in cur_text])\n",
        "    # cur_text=list(cur_text)\n",
        "    # print(cur_text)\n",
        "    return cur_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def basic_cleaning(text):\n",
        "    text=re.sub(r'https?://www\\.\\S+\\.com','',text)\n",
        "    text=re.sub(r'[^A-Za-z|\\s]','',text)\n",
        "    text=re.sub(r'\\*+','swear',text) #capture swear words that are **** out\n",
        "    return text\n",
        "\n",
        "def remove_html(text):\n",
        "    html=re.compile(r'<.*?>')\n",
        "    return html.sub(r'',text)\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "def remove_multiplechars(text):\n",
        "    text = re.sub(r'(.)\\1{3,}',r'\\1', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenization(text):\n",
        "    text=str(text)\n",
        "    text=text.strip()\n",
        "    #text=process_text(text)\n",
        "    text = text.replace('\\n', ' ').replace('\\*', ' ')\n",
        "    # text = re.split(',',text)\n",
        "    # text = re.split('.',text)\n",
        "    text = re.split(' ',text)\n",
        "    return text\n",
        "def remove_dirty_regex(text):\n",
        "    regex = '[^a-zA-Z0-9'+ string.punctuation+']+'\n",
        "    text= [re.sub(regex,\"\",txt) for txt in text]\n",
        "    return text\n",
        "\n",
        "def final_clean(text):\n",
        "    text = [word for word in text if word not in [\"RT\",\" \",\"\"]]\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_bad_starts (text):\n",
        "    bad_starts = [\"@\", \"http\"] # #s to check\n",
        "    return [tx for tx in text if not np.any(list(map(tx.startswith, bad_starts)))] \n",
        "def add_gt(text):\n",
        "    first = \"####\"\n",
        "    txt = copy.deepcopy(text)\n",
        "    text.append(first)\n",
        "    for word in txt:\n",
        "        text.append(word+\"=O\")\n",
        "\n",
        "    text = [word+\" \" if word is not first else word for word in text ]\n",
        "    return ''.join(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"deangraziosi_11May.csv\")\n",
        "df_tweets = df['tweet']\n",
        "# df_lables = df[label_col\n",
        "# df_tweets_np = list(process_text(df_tweets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0          [deangraziosi, What, do, you, mean, by, that]\n",
              "1      [Tiny, Shifts, On, How, To, Be, CONFIDENT, Wit...\n",
              "2                                               [THREAD]\n",
              "3               [LegacyBuilder, sejithesage, Beauvisage]\n",
              "4                     [funguspotion, httpstcoWRYTOvyZzn]\n",
              "                             ...                        \n",
              "119    [deangraziosi, If, you, reflect, on, these, th...\n",
              "120    [deangraziosi, In, the, late, s, my, daughter,...\n",
              "121    [deangraziosi, I, was, pissed, for, failing, b...\n",
              "122    [deangraziosi, Ha, Synchronicity, again, The, ...\n",
              "123    [deangraziosi, Fine, Ill, do, the, laundry, It...\n",
              "Name: tweet, Length: 124, dtype: object"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_tweets_clean = df_tweets.apply(lambda x:basic_cleaning(x))\n",
        "df_tweets_clean = df_tweets_clean.apply(lambda x: remove_emoji(x))\n",
        "df_tweets_clean = df_tweets_clean.apply(lambda x:remove_multiplechars(x))\n",
        "df_tweets_clean = df_tweets_clean.apply(lambda x: remove_html(x))\n",
        "df_tweets_clean =df_tweets_clean.apply(lambda x: tokenization(x))\n",
        "# df_tweets_clean = df_tweets_clean.apply(lambda x: remove_bad_starts(x))\n",
        "# df_tweets_clean = df_tweets_clean.apply(lambda x: remove_dirty_regex(x))\n",
        "# df_tweets_clean = df_tweets_clean.apply(lambda x: remove_emoji(x))\n",
        "# df_tweets_clean = df_tweets_clean.apply(lambda x: remove_html(x))\n",
        "# df_tweets_clean = df_tweets_clean.apply(lambda x: final_clean(x))\n",
        "df_tweets_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_tweets_gt = copy.deepcopy(df_tweets_clean.apply(lambda x: add_gt(x)))\n",
        "df_tweets_gt.to_csv(\"deangraziosi_11May.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1711, 1)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df.dropna(inplace=True)\n",
        "def basic_cleaning(text):\n",
        "    text=re.sub(r'https?://www\\.\\S+\\.com','',text)\n",
        "    text=re.sub(r'[^A-Za-z|\\s]','',text)\n",
        "    text=re.sub(r'\\*+','swear',text) #capture swear words that are **** out\n",
        "    return text\n",
        "\n",
        "def remove_html(text):\n",
        "    html=re.compile(r'<*>')\n",
        "    return html.sub(r'',text)\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "def remove_multiplechars(text):\n",
        "    text = re.sub(r'(.)\\1{3,}',r'\\1', text)\n",
        "    return text\n",
        "def clean(df):\n",
        "    for col in ['tweet']:#,'selected_text']:\n",
        "        df[col]=df[col].astype(str).apply(lambda x:basic_cleaning(x))\n",
        "        df[col]=df[col].astype(str).apply(lambda x:remove_emoji(x))\n",
        "        df[col]=df[col].astype(str).apply(lambda x:remove_html(x))\n",
        "        df[col]=df[col].astype(str).apply(lambda x:remove_multiplechars(x))\n",
        "\n",
        "    return df\n",
        "df_clean = clean(df)\n",
        "df_clean.head()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Louise Jones Catherine Adelle Almond Faye Ches...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Unico difetto il prezzo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I made a payment which said it was successful ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I hope the  gets replaced with the F Tributo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet\n",
              "0  Louise Jones Catherine Adelle Almond Faye Ches...\n",
              "1                            Unico difetto il prezzo\n",
              "2  I made a payment which said it was successful ...\n",
              "3       I hope the  gets replaced with the F Tributo\n",
              "4                                                   "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    Louise Jones Catherine Adelle Almond Faye Ches...\n",
              "1                          Unico difetto il prezzo....\n",
              "2    I made a payment which said it was successful ...\n",
              "3     I hope the 488 gets replaced with the F8 Tributo\n",
              "4                                                    üëç\n",
              "Name: tweet, dtype: object"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_tweets = df['tweet']\n",
        "df_tweets =process_text(df_tweets)\n",
        "df_tweets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       [Louise, Jones, Catherine, Adelle, Almond, Fay...\n",
              "1                        [Unico, difetto, il, prezzo....]\n",
              "2       [I, made, a, payment, which, said, it, was, su...\n",
              "3       [I, hope, the, 488, gets, replaced, with, the,...\n",
              "4                                                      []\n",
              "                              ...                        \n",
              "1914             [Thats, the, one, our, Scott, is, on, x]\n",
              "1915    [Yeah, right., Only, took, me, 7, weeks, to, g...\n",
              "1916    [Barclays, your, service, levels, really, are,...\n",
              "1917    [Love, the, horses., My, local, lloyds, excell...\n",
              "1918    [My, card, was, declined, in, Sainsburys, toda...\n",
              "Name: tweet, Length: 1919, dtype: object"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_tweets_clean =df_tweets.apply(lambda x: tokenization(x))\n",
        "df_tweets_clean = df_tweets_clean.apply(lambda x: remove_bad_starts(x))\n",
        "df_tweets_clean = df_tweets_clean.apply(lambda x: remove_dirty_regex(x))\n",
        "df_tweets_clean = df_tweets_clean.apply(lambda x: final_clean(x))\n",
        "df_tweets_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_gt(text):\n",
        "    first = \"####\"\n",
        "    txt = copy.deepcopy(text)\n",
        "    text.append(first)\n",
        "    for word in txt:\n",
        "        text.append(word+\"=O\")\n",
        "\n",
        "    text = [word+\" \" if word is not first else word for word in text ]\n",
        "    return ''.join(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_tweets_gt = copy.deepcopy(df_tweets_clean.apply(lambda x: add_gt(x)))\n",
        "df_tweets_gt.to_csv(\"HSBC_FACEBOOK_process.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Distrilbert.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
