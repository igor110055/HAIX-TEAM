{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "PaK7QUNGAUKB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import numpy as np\n",
        "import copy\n",
        "import string "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenization(text):\n",
        "    text=str(text)\n",
        "    text = text.replace('\\n', ' ').replace('\\*', ' ').replace(',', ' ')\n",
        "    text = re.split(' ',text)\n",
        "    return text\n",
        "\n",
        "def remove_dirty_regex(text):\n",
        "    regex = '[^a-zA-Z0-9'+ string.punctuation+']+'\n",
        "    text= [re.sub(regex,\"\",txt) for txt in text]\n",
        "    return text\n",
        "\n",
        "def final_clean(text):\n",
        "    text = [word for word in text if word not in [\"RT\",\" \",\"\"]]\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_bad_starts (text):\n",
        "    bad_starts = [\"@\", \"http\"] # #s to check\n",
        "    return [tx for tx in text if not np.any(list(map(tx.startswith, bad_starts)))] \n",
        "def process_text(text):\n",
        "    \"\"\"\n",
        "    process the text and filter some special symbol\n",
        "    :param text:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # string preprocessing and aspect term will not be processed\n",
        "    dot_exist = ('.' in text)\n",
        "    cur_text = text.replace('.', '')\n",
        "    #cur_text = cur_text.replace('-', ' ')\n",
        "    cur_text = cur_text.replace(' - ', ', ').str.strip()\n",
        "    cur_text = cur_text.replace('- ', ' ').str.strip()\n",
        "\n",
        "    # split words and punctuations\n",
        "    if '? ' not in cur_text:\n",
        "        cur_text = cur_text.replace('?', '? ').str.strip()\n",
        "    if '! ' not in cur_text:\n",
        "        cur_text = cur_text.replace('!', '! ').str.strip()\n",
        "    cur_text = cur_text.replace('(', '')\n",
        "    cur_text = cur_text.replace(')', '')\n",
        "    cur_text = cur_text.replace('...', ', ').str.strip('.').str.strip().str.strip(',')\n",
        "    # remove quote\n",
        "    cur_text = cur_text.replace('\"', '')\n",
        "    cur_text = cur_text.replace(\" '\", \" \")\n",
        "    cur_text = cur_text.replace(\"' \", \" \")\n",
        "\n",
        "    cur_text = cur_text.replace(':', ', ')\n",
        "    if dot_exist:\n",
        "        cur_text += '.'\n",
        "        # correct some typos\n",
        "    # mainly for processing English texts\n",
        "    cur_text = cur_text.replace('cant', \"can't\")\n",
        "    cur_text = cur_text.replace('wouldnt', \"wouldn't\")\n",
        "    cur_text = cur_text.replace('dont', \"don't\")\n",
        "    cur_text = cur_text.replace('didnt', \"didn't\")\n",
        "    cur_text = cur_text.replace(\"you 're\", \"you're\")\n",
        "\n",
        "    # replace some special symbol\n",
        "    cur_text = cur_text.replace(u' – ', ', ').str.strip()\n",
        "\n",
        "    cur_text = cur_text.replace(u\"‘\", \"\")\n",
        "    # filter the non-ascii character\n",
        "    # cur_text = ''.join([ch if ord(ch) < 128 else ' ' for ch in cur_text])\n",
        "    return cur_text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    @HatePatroller All @mindvalley students are li...\n",
              "1    RT @AlphaGammaHQ: Conferences are great platfo...\n",
              "2    @AlphaGammaHQ @wobi_en @GIFLondon @Esportsbzsu...\n",
              "3    RT @mindvalley: You asked, we delivered. ÃƒÂ°Ã...\n",
              "4    @dubeji18 Check this one out by @thesleepdocto...\n",
              "Name: tweet, dtype: object"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"mithun.csv\")\n",
        "df_tweets = df['tweet']\n",
        "# df_lables = df[label_col\n",
        "# df_tweets =process_text(df_tweets)\n",
        "df_tweets.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1301, 3)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dropna(inplace=True)\n",
        "def basic_cleaning(text):\n",
        "    text=re.sub(r'https?://www\\.\\S+\\.com','',text)\n",
        "    text=re.sub(r'[^A-Za-z|\\s]','',text)\n",
        "    text=re.sub(r'\\*+','swear',text) #capture swear words that are **** out\n",
        "    return text\n",
        "\n",
        "def remove_html(text):\n",
        "    html=re.compile(r'<.*?>')\n",
        "    return html.sub(r'',text)\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "def remove_multiplechars(text):\n",
        "    text = re.sub(r'(.)\\1{3,}',r'\\1', text)\n",
        "    return text\n",
        "def clean(df):\n",
        "    for col in ['tweet']:#,'selected_text']:\n",
        "        df[col]=df[col].astype(str).apply(lambda x:basic_cleaning(x))\n",
        "        df[col]=df[col].astype(str).apply(lambda x:remove_emoji(x))\n",
        "        df[col]=df[col].astype(str).apply(lambda x:remove_html(x))\n",
        "        df[col]=df[col].astype(str).apply(lambda x:remove_multiplechars(x))\n",
        "\n",
        "    return df\n",
        "df_clean = clean(df)\n",
        "df_clean.head()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>twitterHandlerused</th>\n",
              "      <th>Final_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HatePatroller All mindvalley students are like...</td>\n",
              "      <td>@mindvalley</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT AlphaGammaHQ Conferences are great platform...</td>\n",
              "      <td>@mindvalley</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AlphaGammaHQ wobien GIFLondon Esportsbzsummit ...</td>\n",
              "      <td>@mindvalley</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT mindvalley You asked we delivered \\n\\nFor y...</td>\n",
              "      <td>@mindvalley</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dubeji Check this one out by thesleepdoctor on...</td>\n",
              "      <td>@mindvalley</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet twitterHandlerused  \\\n",
              "0  HatePatroller All mindvalley students are like...        @mindvalley   \n",
              "1  RT AlphaGammaHQ Conferences are great platform...        @mindvalley   \n",
              "2  AlphaGammaHQ wobien GIFLondon Esportsbzsummit ...        @mindvalley   \n",
              "3  RT mindvalley You asked we delivered \\n\\nFor y...        @mindvalley   \n",
              "4  dubeji Check this one out by thesleepdoctor on...        @mindvalley   \n",
              "\n",
              "  Final_labels  \n",
              "0      Neutral  \n",
              "1     Positive  \n",
              "2     Positive  \n",
              "3      Neutral  \n",
              "4      Neutral  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ord() expected a character, but string of length 51 found",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1760/1100764275.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_tweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_tweets\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_tweets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf_tweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1760/2737988175.py\u001b[0m in \u001b[0;36mprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mcur_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu\"‘\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m# filter the non-ascii character\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mcur_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mch\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m128\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m' '\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcur_text\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcur_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1760/2737988175.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mcur_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu\"‘\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m# filter the non-ascii character\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mcur_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mch\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m128\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m' '\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcur_text\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcur_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: ord() expected a character, but string of length 51 found"
          ]
        }
      ],
      "source": [
        "df_tweets = df['tweet']\n",
        "df_tweets =process_text(df_tweets)\n",
        "df_tweets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       [H, a, t, e, P, a, t, r, o, l, l, e, r,  , A, ...\n",
              "1       [R, T,  , A, l, p, h, a, G, a, m, m, a, H, Q, ...\n",
              "2       [A, l, p, h, a, G, a, m, m, a, H, Q,  , w, o, ...\n",
              "3       [R, T,  , m, i, n, d, v, a, l, l, e, y, :,  , ...\n",
              "4       [d, u, b, e, j, i, 1, 8,  , C, h, e, c, k,  , ...\n",
              "                              ...                        \n",
              "1296    [I,  , h, a, v, e,  , c, o, m, p, l, e, t, e, ...\n",
              "1297    [S, o, p, h, i, e, E, d, e, n, 1, 2,  , m, i, ...\n",
              "1298    [T, h, e,  , I, m, P, a, u, l, M, c, K, e, n, ...\n",
              "1299    [m, i, n, d, v, a, l, l, e, y,  , V, i, s, h, ...\n",
              "1300    [E, r, i, c, E, d, m, e, a, d, e, s,  , g, a, ...\n",
              "Name: tweet, Length: 1301, dtype: object"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df_tweets_clean =df_tweets.apply(lambda x: tokenization(x))\n",
        "df_tweets_clean = df_tweets.apply(lambda x: remove_bad_starts(x))\n",
        "# df_tweets_clean = df_tweets_clean.apply(lambda x: remove_dirty_regex(x))\n",
        "# df_tweets_clean = df_tweets_clean.apply(lambda x: final_clean(x))\n",
        "# df_tweets_clean =process_text(df_tweets_clean)\n",
        "df_tweets_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "Can only use .str accessor with string values!",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1760/1502365299.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_tweets_clean\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_tweets_clean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1760/2615601239.py\u001b[0m in \u001b[0;36mprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m#cur_text = cur_text.replace('-', ' ')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mcur_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' - '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mcur_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'- '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# split words and punctuations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0maccessor_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[1;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\strings\\accessor.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inferred_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_categorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\strings\\accessor.py\u001b[0m in \u001b[0;36m_validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minferred_dtype\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallowed_types\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can only use .str accessor with string values!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
          ]
        }
      ],
      "source": [
        "df_tweets_clean =process_text(df_tweets_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Distrilbert.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
